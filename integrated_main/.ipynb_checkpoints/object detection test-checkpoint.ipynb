{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c84fa6",
   "metadata": {},
   "source": [
    "# object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "308c2695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import base64\n",
    "import codecs, json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from PIL import Image\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "#from keras_retinanet.utils.gpu import setup_gpu\n",
    "from keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6047f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['main.py',\n",
       " 'person_data',\n",
       " 'image_retrieval.py',\n",
       " 'retrieval_data',\n",
       " 'output',\n",
       " '.ipynb_checkpoints',\n",
       " 'keras-retinanet',\n",
       " '__pycache__',\n",
       " 'test.ipynb',\n",
       " 'object_detection.py',\n",
       " 'src',\n",
       " 'person_output']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "986c0e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/plass-heesu/anaconda3/envs/tf1.15/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_1:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_2:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_3:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_4:0' shape=(9, 4) dtype=float32> anchors\n",
      "WARNING:tensorflow:From /home/plass-heesu/anaconda3/envs/tf1.15/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/plass-heesu/.local/lib/python3.6/site-packages/keras_retinanet/backend/tensorflow_backend.py:68: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/plass-heesu/.local/lib/python3.6/site-packages/keras_retinanet/backend/tensorflow_backend.py:104: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plass-heesu/anaconda3/envs/tf1.15/lib/python3.6/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "os.path.join('./keras-retinanet', 'snapshots', 'resnet50_coco_best_v2.1.0.h5')\n",
    "\n",
    "model_path = os.path.join('./keras-retinanet', 'snapshots', 'resnet50_coco_best_v2.1.0.h5')\n",
    "\n",
    "#데이터셋 경로\n",
    "dataset_path = './person_data/'\n",
    "output_path = './train/'\n",
    "\n",
    "\n",
    "retina_model = models.load_model(model_path, backbone_name='resnet50')\n",
    "os.chdir(dataset_path)\n",
    "dataset_list = os.listdir(os.getcwd())\n",
    "os.chdir('../')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f02fcd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train', 'test']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./retrieval_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101b8bdc",
   "metadata": {},
   "source": [
    "# object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60a10618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling person000031.png\n",
      "image shape: (428, 640, 3)\n",
      "resized image size: (800, 1196, 3) scale: 1.8691588785046729\n",
      "WARNING:tensorflow:From /home/plass-heesu/anaconda3/envs/tf1.15/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "(1, 300, 4) (1, 300) (1, 300)\n",
      "processing time:  3.1836273670196533\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './retrieval_data/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-93150acbbb0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mobject_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretina_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/KimHeeSu/2021-1-CECD3-four-elSe-1/main/object_detection.py\u001b[0m in \u001b[0;36mobject_detection\u001b[0;34m(model, image_array, dataset_path)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# 객체 dump\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mobject_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}_path: ({}).jpg\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_to_names_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_to_num\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimagePath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './retrieval_data/train/'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "from object_detection import object_detection\n",
    "object_detection(retina_model, dataset_list, dataset_path,output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d72498e",
   "metadata": {},
   "source": [
    "# image retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8d13ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['main.py',\n",
       " 'person_data',\n",
       " 'image_retrieval.py',\n",
       " 'retrieval_data',\n",
       " 'output',\n",
       " '.ipynb_checkpoints',\n",
       " 'keras-retinanet',\n",
       " '__pycache__',\n",
       " 'test.ipynb',\n",
       " 'object_detection.py',\n",
       " 'src',\n",
       " 'person_output']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d865b26a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf115",
   "language": "python",
   "name": "tf115"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
