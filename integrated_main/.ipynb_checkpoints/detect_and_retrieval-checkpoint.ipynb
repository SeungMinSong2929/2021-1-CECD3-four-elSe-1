{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742dd40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import base64\n",
    "import codecs, json\n",
    "import pickle\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "#from keras_retinanet.utils.gpu import setup_gpu\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "# object detection\n",
    "os.path.join('./keras-retinanet', 'snapshots', 'resnet50_coco_best_v2.1.0.h5')\n",
    "\n",
    "model_path = os.path.join('./keras-retinanet', 'snapshots', 'resnet50_coco_best_v2.1.0.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6396147",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./person_data/\"\n",
    "output_path = \"./retrieval_data/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b28696",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retina_model = models.load_model(model_path, backbone_name='resnet50')\n",
    "os.chdir(dataset_path)\n",
    "dataset_list = os.listdir(os.getcwd())\n",
    "os.chdir('../')\n",
    "\n",
    "\n",
    "from object_detection import object_detection\n",
    "object_detection(retina_model, dataset_list, dataset_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e35bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_retrieval import image_retrieval\n",
    "from tqdm import tqdm\n",
    "\n",
    "images_path = glob(\"./retrieval_data/train/*.jpg\")\n",
    "\n",
    "for path in tqdm(images_path):\n",
    "    image_pil = Image.open(path)\n",
    "    image_resized = image_pil.resize((512,512))\n",
    "    image_resized.save(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f304e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try: \"simpleAE\", \"convAE\", \"vgg19\" , \"IncepResNet\", \"ResNet50v2\"\n",
    "#     modelName = \"IncepResNet\"  # try: \"simpleAE\", \"convAE\", \"vgg19\" , \"IncepResNet\", \"ResNet50v2\"\n",
    "#     trainModel = True\n",
    "#     parallel = False  # use multicore processing\n",
    "image_retrieval(modelName=\"ResNet50v2\",trainModel=True, parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdce130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
